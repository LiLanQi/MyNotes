# 论文笔记

## 1.Few-Shot Graph Learning for Molecular Property Prediction

```bash
@article{guo2021few,
  title={Few-Shot Graph Learning for Molecular Property Prediction},
  author={Guo, Zhichun and Zhang, Chuxu and Yu, Wenhao and Herr, John and Wiest, Olaf and Jiang, Meng and Chawla, Nitesh V},
  journal={arXiv preprint arXiv:2102.07916},
  year={2021}
}
```

![image-20220518173212392](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518173212392.png)总结：

- 提出了Meta-MGNN，总体架构如图a)，首先从训练task中sample出一些数据作为Supprot set，将这些数据放入参数为θ的GNN中训练，算出损失ℒsupport，然后利用这个损失去优化θ得到θ’，之后再将Query set中的数据放入参数为θ’的GNN中训练，算出ℒ‘query,将所有任务的ℒ‘query,都加起来得到整体损失，然后对模型继续优化

- 损失函数 ![image-20220518180201411](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518180201411.png)，具体如下

  - 分子属性预测损失：预测lables与ground-truth lables之间的CROSSENTROPY

    ![image-20220518180125844](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518180125844.png)

  - 键重构损失：从图中sample出存在边的positive edges与不存在边的negative edges作为集合![image-20220518175344515](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518175344515.png)，然后通过俩个结点之间的内积来计算建重构分数![image-20220518175438363](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518175438363.png)，最后得到键重构损失

    ![image-20220518175123755](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518175123755.png)

  - 原子类型预测损失：在图中sample出一些结点作为子图![image-20220518175802709](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518175802709.png)，对每个结点，我们利用它的一阶邻居来预测该原子类型，将邻居结点feature加起来求mean后通过一个MLP得到预测的类型，再与真实lable进行对比算loss即可

    ![image-20220518180000783](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518180000783.png)

    

- 任务意识注意力：考虑到不同的属性预测任务对元学习优化的贡献不用，引入Task-aware Attention，如下：

  ![image-20220518192119971](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518192119971.png)

  以此来更新θ

  ![image-20220518192316597](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518192316597.png)

- 根据训练Task中的Supprot set来更新θ得到θ’，用该θ’来训练Query set，然后θ’->θ,把所有训练Task的在Query set中得到的LOSS加起来得到总的LOSS，然后再更新参数，即参数更新方向与第二次梯度下降方向一致，如图

  ![image-20220518214736914](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220518214736914.png)

## 2.Design Space for Graph Neural Networks

```bash
@InProceedings{you2020design,
  title = {Design Space for Graph Neural Networks},
  author = {You, Jiaxuan and Ying, Rex and Leskovec, Jure},
  booktitle = {NeurIPS},
  year = {2020}
}
```

主要讲了如何设计GNN，快速的找到适合的GNN模型以及参数等问题。
